"""
æ—¥å¿—ç®¡ç†å™¨

æä¾›å•ä¾‹æ—¥å¿—ç®¡ç†å™¨å’Œé€šç”¨æ—¥å¿—ç®¡ç†åŠŸèƒ½ã€‚
"""

import os
import sys
import json
import logging
import logging.handlers
import threading
from datetime import datetime
from pathlib import Path
from typing import Optional

from .config import LogConfig


class SingletonLogger:
    """å•ä¾‹æ—¥å¿—ç®¡ç†å™¨ï¼Œç¡®ä¿å…¨å±€åªæœ‰ä¸€ä¸ªæ—¥å¿—å®ä¾‹"""
    
    _instance = None
    _lock = threading.Lock()
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not self._initialized:
            self.logger = None
            self.config = None
            self.log_file_path = None
            self._initialized = True
    
    def setup(self, config: LogConfig, log_file: Optional[str] = None) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        if self.logger is not None:
            # å¦‚æœå·²ç»åˆå§‹åŒ–è¿‡ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°æ—¥å¿—çº§åˆ«
            if self.config and self.config.log_level != config.log_level:
                # æ›´æ–°æ—¥å¿—çº§åˆ«
                self.logger.setLevel(getattr(logging, config.log_level.upper()))
                # æ›´æ–°æ‰€æœ‰å¤„ç†å™¨çš„çº§åˆ«
                for handler in self.logger.handlers:
                    handler.setLevel(getattr(logging, config.log_level.upper()))
                self.config.log_level = config.log_level
                print(f"ğŸ”„ æ—¥å¿—çº§åˆ«å·²æ›´æ–°ä¸º: {config.log_level}")
            return self.logger
        
        self.config = config
        self.logger = logging.getLogger('llmjson')
        self.logger.setLevel(getattr(logging, config.log_level.upper()))
        
        # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
        self.logger.handlers.clear()
        
        # è®¾ç½®æ—¥å¿—æ–‡ä»¶è·¯å¾„
        if log_file is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            os.makedirs(config.log_dir, exist_ok=True)
            self.log_file_path = os.path.join(config.log_dir, f"llmjson_{timestamp}.log")
        else:
            self.log_file_path = log_file
        
        # æ·»åŠ å¤„ç†å™¨
        self._add_console_handler()
        self._add_file_handlers()
        
        # è®°å½•æ—¥å¿—ç³»ç»Ÿå¯åŠ¨ä¿¡æ¯
        self._log_startup_info()
        
        return self.logger
    
    def _add_console_handler(self):
        """æ·»åŠ æ§åˆ¶å°å¤„ç†å™¨"""
        if not self.config.enable_console:
            return
        
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(getattr(logging, self.config.log_level.upper()))
        
        console_formatter = logging.Formatter(self.config.console_format)
        console_handler.setFormatter(console_formatter)
        
        self.logger.addHandler(console_handler)
    
    def _add_file_handlers(self):
        """æ·»åŠ æ–‡ä»¶å¤„ç†å™¨"""
        if not self.config.enable_file:
            return
        
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(self.log_file_path), exist_ok=True)
        
        # ä¸»æ—¥å¿—æ–‡ä»¶å¤„ç†å™¨ï¼ˆä½¿ç”¨è½®è½¬ï¼‰
        if self.config.enable_async:
            # å¼‚æ­¥æ–‡ä»¶å¤„ç†å™¨
            from concurrent.futures import ThreadPoolExecutor
            file_handler = AsyncFileHandler(
                self.log_file_path,
                maxBytes=self.config.max_file_size,
                backupCount=self.config.backup_count,
                encoding='utf-8'
            )
        else:
            file_handler = logging.handlers.RotatingFileHandler(
                self.log_file_path,
                maxBytes=self.config.max_file_size,
                backupCount=self.config.backup_count,
                encoding='utf-8'
            )
        
        file_handler.setLevel(logging.DEBUG)
        
        if self.config.enable_json:
            file_formatter = JsonFormatter(self.config.json_format)
        else:
            file_formatter = logging.Formatter(self.config.file_format)
        
        file_handler.setFormatter(file_formatter)
        self.logger.addHandler(file_handler)
        
        # é”™è¯¯æ—¥å¿—å•ç‹¬æ–‡ä»¶
        if self.config.separate_error_log:
            self._add_error_handler()
    
    def _add_error_handler(self):
        """æ·»åŠ é”™è¯¯æ—¥å¿—å¤„ç†å™¨"""
        error_log_file = self.log_file_path.replace('.log', '_error.log')
        error_handler = logging.handlers.RotatingFileHandler(
            error_log_file,
            maxBytes=self.config.max_file_size,
            backupCount=self.config.backup_count,
            encoding='utf-8'
        )
        error_handler.setLevel(logging.ERROR)
        
        if self.config.enable_json:
            error_formatter = JsonFormatter(self.config.json_format)
        else:
            error_formatter = logging.Formatter(self.config.file_format)
        
        error_handler.setFormatter(error_formatter)
        self.logger.addHandler(error_handler)
    
    def _log_startup_info(self):
        """è®°å½•æ—¥å¿—ç³»ç»Ÿå¯åŠ¨ä¿¡æ¯"""
        self.logger.info("=" * 60)
        self.logger.info("ğŸ”§ æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        self.logger.info(f"ğŸ“„ æ—¥å¿—æ–‡ä»¶: {os.path.abspath(self.log_file_path)}")
        self.logger.info(f"ğŸ“Š æ—¥å¿—çº§åˆ«: {self.config.log_level}")
        self.logger.info(f"ğŸ’¾ æœ€å¤§æ–‡ä»¶å¤§å°: {self.config.max_file_size // 1024 // 1024}MB")
        self.logger.info(f"ğŸ“¦ å¤‡ä»½æ–‡ä»¶æ•°: {self.config.backup_count}")
        if self.config.enable_async:
            self.logger.info("âš¡ å¼‚æ­¥æ—¥å¿—å·²å¯ç”¨")
        if self.config.enable_json:
            self.logger.info("ğŸ“‹ JSONæ ¼å¼æ—¥å¿—å·²å¯ç”¨")
        self.logger.info("=" * 60)
    
    def get_logger(self) -> Optional[logging.Logger]:
        """è·å–æ—¥å¿—å™¨å®ä¾‹"""
        return self.logger
    
    def cleanup_old_logs(self):
        """æ¸…ç†æ—§æ—¥å¿—æ–‡ä»¶"""
        if not self.config or not self.config.auto_cleanup:
            return
        
        try:
            log_dir = Path(self.config.log_dir)
            if not log_dir.exists():
                return
            
            cutoff_time = datetime.now().timestamp() - (self.config.max_days * 24 * 3600)
            
            cleaned_files = 0
            for log_file in log_dir.glob("*.log*"):
                if log_file.stat().st_mtime < cutoff_time:
                    try:
                        log_file.unlink()
                        cleaned_files += 1
                    except Exception as e:
                        if self.logger:
                            self.logger.warning(f"æ— æ³•åˆ é™¤æ—¥å¿—æ–‡ä»¶ {log_file}: {e}")
            
            if cleaned_files > 0 and self.logger:
                self.logger.info(f"ğŸ§¹ æ¸…ç†äº† {cleaned_files} ä¸ªè¿‡æœŸæ—¥å¿—æ–‡ä»¶")
                
        except Exception as e:
            if self.logger:
                self.logger.error(f"æ¸…ç†æ—¥å¿—æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    def reset(self):
        """é‡ç½®æ—¥å¿—ç®¡ç†å™¨ï¼ˆä¸»è¦ç”¨äºæµ‹è¯•ï¼‰"""
        if self.logger:
            self.logger.handlers.clear()
        self.logger = None
        self.config = None
        self.log_file_path = None


class LogManager:
    """é€šç”¨æ—¥å¿—ç®¡ç†å™¨ï¼ˆéå•ä¾‹ï¼‰"""
    
    def __init__(self, config: LogConfig):
        self.config = config
        self.logger = None
    
    def setup_logging(self, logger_name: str = 'llmjson') -> logging.Logger:
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        self.logger = logging.getLogger(logger_name)
        self.logger.setLevel(getattr(logging, self.config.log_level.upper()))
        
        # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
        self.logger.handlers.clear()
        
        # æ·»åŠ å¤„ç†å™¨
        if self.config.enable_console:
            self._add_console_handler()
        
        if self.config.enable_file:
            self._add_file_handlers()
        
        return self.logger
    
    def _add_console_handler(self):
        """æ·»åŠ æ§åˆ¶å°å¤„ç†å™¨"""
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(getattr(logging, self.config.log_level.upper()))
        
        console_formatter = logging.Formatter(self.config.console_format)
        console_handler.setFormatter(console_formatter)
        
        self.logger.addHandler(console_handler)
    
    def _add_file_handlers(self):
        """æ·»åŠ æ–‡ä»¶å¤„ç†å™¨"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        os.makedirs(self.config.log_dir, exist_ok=True)
        log_file_path = os.path.join(self.config.log_dir, f"llmjson_{timestamp}.log")
        
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(log_file_path), exist_ok=True)
        
        # ä¸»æ—¥å¿—æ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.handlers.RotatingFileHandler(
            log_file_path,
            maxBytes=self.config.max_file_size,
            backupCount=self.config.backup_count,
            encoding='utf-8'
        )
        file_handler.setLevel(logging.DEBUG)
        
        if self.config.enable_json:
            file_formatter = JsonFormatter(self.config.json_format)
        else:
            file_formatter = logging.Formatter(self.config.file_format)
        
        file_handler.setFormatter(file_formatter)
        self.logger.addHandler(file_handler)


class JsonFormatter(logging.Formatter):
    """JSONæ ¼å¼åŒ–å™¨"""
    
    def __init__(self, format_dict):
        super().__init__()
        self.format_dict = format_dict
    
    def format(self, record):
        # é¦–å…ˆè°ƒç”¨çˆ¶ç±»çš„formatæ¥ç¡®ä¿recordæœ‰æ­£ç¡®çš„å±æ€§
        self.formatTime(record)  # ç¡®ä¿asctimeå±æ€§å­˜åœ¨
        
        log_entry = {}
        for key, value in self.format_dict.items():
            try:
                # ä½¿ç”¨æ ‡å‡†çš„LogRecordæ ¼å¼åŒ–
                if isinstance(value, str) and '%(' in value:
                    formatted_value = value % record.__dict__
                else:
                    formatted_value = value
                log_entry[key] = formatted_value
            except (KeyError, ValueError, TypeError):
                # å¦‚æœæ ¼å¼åŒ–å¤±è´¥ï¼Œå°è¯•ç›´æ¥ä»recordè·å–å±æ€§
                if key == 'timestamp':
                    log_entry[key] = self.formatTime(record)
                elif key == 'message':
                    log_entry[key] = record.getMessage()
                elif key == 'level':
                    log_entry[key] = record.levelname
                elif key == 'filename':
                    log_entry[key] = record.filename
                elif key == 'lineno':
                    log_entry[key] = record.lineno
                elif key == 'name':
                    log_entry[key] = record.name
                else:
                    log_entry[key] = str(value)
        
        # æ·»åŠ å¼‚å¸¸ä¿¡æ¯
        if record.exc_info:
            log_entry['exception'] = self.formatException(record.exc_info)
        
        return json.dumps(log_entry, ensure_ascii=False)


class AsyncFileHandler(logging.handlers.RotatingFileHandler):
    """å¼‚æ­¥æ–‡ä»¶å¤„ç†å™¨"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        from concurrent.futures import ThreadPoolExecutor
        self.executor = ThreadPoolExecutor(max_workers=1, thread_name_prefix="AsyncLogger")
    
    def emit(self, record):
        """å¼‚æ­¥å‘å‡ºæ—¥å¿—è®°å½•"""
        self.executor.submit(super().emit, record)
    
    def close(self):
        """å…³é—­å¤„ç†å™¨"""
        if hasattr(self, 'executor'):
            self.executor.shutdown(wait=True)
        super().close()
