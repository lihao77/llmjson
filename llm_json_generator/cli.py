#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLM JSON Generator å‘½ä»¤è¡Œæ¥å£

æä¾›å‘½ä»¤è¡Œå·¥å…·æ¥ä½¿ç”¨LLM JSON GeneratoråŒ…çš„åŠŸèƒ½ã€‚
"""

import argparse
import sys
import os
from pathlib import Path
from typing import List, Optional
from datetime import datetime

from .processor import LLMProcessor
from .config import ConfigManager
from .utils import (
    ensure_dir, 
    save_json, 
    load_json,
    chunk_text,
    Timer,
    sanitize_filename,
    merge_knowledge_graph_results
)
from .log import (
    setup_logging,
    get_logger,
    create_logger_with_context,
    create_timed_logger,
    log_execution_time,
    log_system_info
)
from .exceptions import LLMProcessingError, ValidationError
from .word_chunker import WordChunker
from .run_mode import DocumentProcessor


@log_execution_time()
def create_config_command(args):
    """åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶"""
    logger = create_logger_with_context({
        'command': 'create_config',
        'output': args.output or 'config.json'
    })
    
    logger.info("ğŸ”§ å¼€å§‹åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶")
    
    config = ConfigManager()
    
    # è®¾ç½®é»˜è®¤LLMé…ç½®
    config.llm_config.api_key = "your-openai-api-key-here"
    config.llm_config.model = "gpt-4o-mini"
    config.llm_config.temperature = 0.1
    config.llm_config.max_tokens = 4000
    config.llm_config.max_retries = 3
    config.llm_config.timeout = 60
    
    # è®¾ç½®é»˜è®¤å¤„ç†é…ç½®
    config.processing_config.chunk_size = 2000
    config.processing_config.chunk_overlap = 200
    config.processing_config.max_workers = 4
    config.processing_config.enable_parallel = True
    
    # ä¿å­˜é…ç½®æ–‡ä»¶
    config_file = args.output or "config.json"
    config.save_to_file(config_file)
    
    logger.info(f"âœ… ç¤ºä¾‹é…ç½®æ–‡ä»¶å·²åˆ›å»º: {config_file}")
    print(f"âœ… ç¤ºä¾‹é…ç½®æ–‡ä»¶å·²åˆ›å»º: {config_file}")
    print("âš ï¸  è¯·ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼Œè®¾ç½®ä½ çš„OpenAI APIå¯†é’¥")
    print(f"ğŸ“ ç¼–è¾‘å‘½ä»¤: notepad {config_file}" if os.name == 'nt' else f"ğŸ“ ç¼–è¾‘å‘½ä»¤: nano {config_file}")


@log_execution_time()
def process_text_command(args):
    """å¤„ç†å•ä¸ªæ–‡æœ¬æ–‡ä»¶"""
    # åˆ›å»ºä¸Šä¸‹æ–‡æ—¥å¿—å™¨
    logger = create_logger_with_context({
        'command': 'process_text',
        'document_path': args.document_path,
        'output': args.output or 'output',
        'config': args.config or 'config.json'
    })
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.document_path):
        error_msg = f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.document_path}"
        logger.error(f"âŒ {error_msg}")
        print(f"âŒ {error_msg}")
        return 1
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    config_file = args.config or "config.json"
    if not os.path.exists(config_file):
        error_msg = f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}"
        logger.error(f"âŒ {error_msg}")
        print(f"âŒ {error_msg}")
        print("ğŸ’¡ ä½¿ç”¨ 'llm-json-generator create-config' åˆ›å»ºé…ç½®æ–‡ä»¶")
        return 1
    
    try:
        # è®¾ç½®æ—¥å¿—çº§åˆ«
        log_level = "DEBUG" if args.log else "INFO"
        main_logger = setup_logging(log_level)
        
        # è®°å½•ç³»ç»Ÿä¿¡æ¯
        if args.log:
            log_system_info()
        
        logger.info("ğŸ¤– åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨...")
        # åˆ›å»ºæ–‡æ¡£å¤„ç†å™¨
        print("ğŸ¤– åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨...")
        processor = DocumentProcessor(config_file, args.template)
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = args.output or "output"
        
        # å¤„ç†å•ä¸ªæ–‡æ¡£
        logger.info(f"ğŸš€ å¼€å§‹å¤„ç†æ–‡æ¡£: {args.document_path}")
        print(f"ğŸš€ å¼€å§‹å¤„ç†æ–‡æ¡£: {args.document_path}")

        result = processor.process_single_document(
                document_path=args.document_path,
                base_output_dir=output_dir,
                include_tables=args.tables,
                generate_validation_report=args.validation
            )
        
        if result['success']:
            # è®°å½•å¤„ç†ç»“æœ
            logger.info(f"âœ… æ–‡æ¡£å¤„ç†æˆåŠŸï¼Œè€—æ—¶: {result['processing_time']:.2f}ç§’")
            logger.info(f"ğŸ“¦ å¤„ç†ç»Ÿè®¡ - æ€»å—æ•°: {result['chunks']['total']}, "
                       f"æˆåŠŸ: {result['chunks']['successful']}, "
                       f"å¤±è´¥: {result['chunks']['failed']}")
            
            # è¾“å‡ºæ‘˜è¦
            print("\n" + "="*50)
            print("ğŸ“Š å¤„ç†å®Œæˆæ‘˜è¦")
            print("="*50)
            print(f"â±ï¸  å¤„ç†è€—æ—¶: {result['processing_time']:.2f}ç§’")
            print(f"ğŸ“¦ æ–‡æœ¬å—æ•°: {result['chunks']['total']}")
            print(f"âœ… æˆåŠŸå¤„ç†: {result['chunks']['successful']}")
            print(f"âŒ å¤„ç†å¤±è´¥: {result['chunks']['failed']}")
            print(f"ğŸ“ˆ æˆåŠŸç‡: {result['chunks']['success_rate']:.1f}%")
            print(f"ğŸ·ï¸  æå–å®ä½“: {result['entities']['total']}ä¸ª (åŸºç¡€: {result['entities']['basic_entities']}, çŠ¶æ€: {result['entities']['state_entities']})")
            print(f"ğŸ”— æå–å…³ç³»: {result['relations']['total']}ä¸ª")
            print(f"ğŸ“ è¾“å‡ºç›®å½•: {result['output_directory']}")
            
            if result['chunks']['failed'] > 0:
                warning_msg = f"æœ‰ {result['chunks']['failed']} ä¸ªæ–‡æœ¬å—å¤„ç†å¤±è´¥"
                logger.warning(f"âš ï¸ {warning_msg}")
                print(f"\nâš ï¸  {warning_msg}ï¼Œè¯¦æƒ…è¯·æŸ¥çœ‹å¤±è´¥æŠ¥å‘Š")
                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¤±è´¥æ–‡ä»¶è®°å½•
                if result.get('files', {}).get('failed_file'):
                    print(f"ğŸ“„ å¤±è´¥æŠ¥å‘Š: {result['files']['failed_file']}")
                elif result.get('files', {}).get('chunks_results'):
                    print(f"ğŸ“„ è¯¦ç»†ç»“æœ: {result['files']['chunks_results']}")
                        
            return 0
        else:
            error_msg = f"å¤„ç†å¤±è´¥: {result['error']}"
            logger.error(f"âŒ {error_msg}")
            print(f"âŒ {error_msg}")
            return 1
        
    except Exception as e:
        error_msg = f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}"
        logger.error(f"âŒ {error_msg}")
        print(f"âŒ {error_msg}")
        if args.log:
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            traceback.print_exc()
        return 1


@log_execution_time()
def process_documents_command(args):
    """å¤„ç†æ–‡æ¡£æ–‡ä»¶å¤¹"""
    # åˆ›å»ºä¸Šä¸‹æ–‡æ—¥å¿—å™¨
    logger = create_logger_with_context({
        'command': 'process_documents',
        'folder_path': args.folder_path,
        'mode': args.mode or 'optimized',
        'output': args.output or 'output',
        'config': args.config or 'config.json'
    })
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    config_file = args.config or "config.json"
    if not os.path.exists(config_file):
        error_msg = f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}"
        logger.error(f"âŒ {error_msg}")
        print(f"âŒ {error_msg}")
        print("ğŸ’¡ ä½¿ç”¨ 'llm-json-generator create-config' åˆ›å»ºé…ç½®æ–‡ä»¶")
        return 1
    
    # è·å–æ–‡ä»¶å¤¹è·¯å¾„
    folder_path = args.folder_path
    
    # éªŒè¯æ–‡ä»¶å¤¹å­˜åœ¨æ€§
    if not os.path.exists(folder_path):
        error_msg = f"æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}"
        logger.error(f"âŒ {error_msg}")
        print(f"âŒ {error_msg}")
        return 1
    
    if not os.path.isdir(folder_path):
        error_msg = f"æŒ‡å®šçš„è·¯å¾„ä¸æ˜¯æ–‡ä»¶å¤¹: {folder_path}"
        logger.error(f"âŒ {error_msg}")
        print(f"âŒ {error_msg}")
        return 1
    
    logger.info(f"ğŸ“ å‡†å¤‡å¤„ç†æ–‡ä»¶å¤¹: {folder_path}")
    print(f"ğŸ“ å‡†å¤‡å¤„ç†æ–‡ä»¶å¤¹: {folder_path}")
    
    try:
        # è®¾ç½®æ—¥å¿—çº§åˆ«
        log_level = "DEBUG" if args.log else "INFO"
        main_logger = setup_logging(log_level)
        
        # è®°å½•ç³»ç»Ÿä¿¡æ¯
        if args.log:
            log_system_info()
        
        logger.info("ğŸ¤– åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨...")
        # åˆ›å»ºæ–‡æ¡£å¤„ç†å™¨
        print("ğŸ¤– åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨...")
        processor = DocumentProcessor(config_file, args.template)
        
        # ç¡®å®šå¤„ç†æ¨¡å¼
        mode = args.mode or "optimized"
        if mode not in ["batch", "optimized"]:
            error_msg = f"ä¸æ”¯æŒçš„å¤„ç†æ¨¡å¼: {mode}"
            logger.error(f"âŒ {error_msg}")
            print(f"âŒ {error_msg}")
            print("ğŸ’¡ æ”¯æŒçš„æ¨¡å¼: batch , optimized ")
            return 1
        
        mode_names = {
            "batch": "ä¼ ç»Ÿæ‰¹é‡å¤„ç†",
            "optimized": "ä¼˜åŒ–æµå¼å¤„ç†"
        }
        
        logger.info(f"âœ… å·²é€‰æ‹©å¤„ç†æ¨¡å¼: {mode_names[mode]}")
        print(f"\nâœ… å·²é€‰æ‹©: {mode_names[mode]}")
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        output_dir = args.output or "output"
        
        # å¼€å§‹å¤„ç†
        logger.info(f"ğŸ”„ å¼€å§‹{mode_names[mode]}...")
        print(f"\nğŸ”„ å¼€å§‹{mode_names[mode]}...")
        
        # ä½¿ç”¨è®¡æ—¶ä¸Šä¸‹æ–‡æ—¥å¿—å™¨
        timed_logger = create_timed_logger({
            'operation': f'{mode}_processing',
            'folder': folder_path
        })
        
        with timed_logger.time_context("document_processing"):
            if mode == "batch":
                results = processor.process_document_list_batch(
                    folder_path=folder_path,
                    base_output_dir=output_dir,
                    include_tables=args.tables,
                    generate_validation_report=args.validation
                )
            else:  # optimized
                results = processor.process_document_list_streaming_optimized(
                    folder_path=folder_path,
                    base_output_dir=output_dir,
                    include_tables=args.tables,
                    generate_validation_report=args.validation
                )
        
        # è®°å½•å¤„ç†ç»“æœ
        success_rate = results['summary']['documents']['success_rate']
        logger.info(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼æˆåŠŸç‡: {success_rate:.1f}%")
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {results['processing_info']['output_directory']}")
        
        print(f"\nğŸ‰ æ‰€æœ‰å¤„ç†å®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {results['processing_info']['output_directory']}")
        
        # è¿”å›æˆåŠŸç‡ä½œä¸ºé€€å‡ºç 
        return 0 if success_rate > 80 else 1
        
    except Exception as e:
        error_msg = f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}"
        logger.error(f"âŒ {error_msg}")
        print(f"âŒ {error_msg}")
        if args.log:
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            traceback.print_exc()
        return 1


@log_execution_time()
def validate_command(args):
    """éªŒè¯JSONæ•°æ®"""
    from .validator import DataValidator
    
    # åˆ›å»ºä¸Šä¸‹æ–‡æ—¥å¿—å™¨
    logger = create_logger_with_context({
        'command': 'validate',
        'input': args.input,
        'output': args.output,
        'report': args.report
    })
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input):
        error_msg = f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}"
        logger.error(f"âŒ {error_msg}")
        print(f"âŒ {error_msg}")
        return 1
    
    try:
        # åŠ è½½æ•°æ®
        logger.info(f"ğŸ“– å¼€å§‹åŠ è½½æ•°æ®: {args.input}")
        print(f"ğŸ“– åŠ è½½æ•°æ®: {args.input}")
        data = load_json(args.input)
        logger.info(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼Œè®°å½•æ•°: {len(data) if isinstance(data, list) else 1}")
        
        # åˆ›å»ºéªŒè¯å™¨
        logger.info("ğŸ” åˆ›å»ºæ•°æ®éªŒè¯å™¨...")
        validator = DataValidator()
        
        # éªŒè¯æ•°æ®
        logger.info("ğŸ” å¼€å§‹éªŒè¯æ•°æ®...")
        print("ğŸ” éªŒè¯æ•°æ®...")
        
        # ä½¿ç”¨è®¡æ—¶ä¸Šä¸‹æ–‡æ—¥å¿—å™¨
        timed_logger = create_timed_logger({'operation': 'data_validation'})
        
        with timed_logger.time_context("validation"):
            validated_data, validation_report = validator.validate_data(data)
        
        # è·å–éªŒè¯æŠ¥å‘Š
        summary = validator.get_validation_summary()
        full_report = validator.get_validation_report()
        
        # è®°å½•éªŒè¯ç»“æœ
        logger.info(f"âœ… éªŒè¯å®Œæˆ - æˆåŠŸç‡: {summary['success_rate']:.1f}%, "
                   f"é”™è¯¯: {summary['error_count']}, "
                   f"è­¦å‘Š: {summary['warning_count']}, "
                   f"ä¿®å¤: {summary['correction_count']}")
        
        # è¾“å‡ºç»“æœ
        print("\n" + "="*40)
        print("ğŸ“Š éªŒè¯ç»“æœ")
        print("="*40)
        print(f"âœ… éªŒè¯æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        print(f"âŒ é”™è¯¯æ•°é‡: {summary['error_count']}")
        print(f"âš ï¸  è­¦å‘Šæ•°é‡: {summary['warning_count']}")
        print(f"ğŸ”§ ä¿®å¤æ•°é‡: {summary['correction_count']}")
        
        if full_report.get('errors_deleted'):
            logger.info(f"âŒ å‘ç° {len(full_report['errors_deleted'])} ä¸ªé”™è¯¯")
            print("\nâŒ é”™è¯¯è¯¦æƒ…:")
            for error in full_report['errors_deleted'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                print(f"  - {error}")
            if len(full_report['errors_deleted']) > 5:
                print(f"  ... è¿˜æœ‰ {len(full_report['errors_deleted']) - 5} ä¸ªé”™è¯¯")
        
        # ä¿å­˜éªŒè¯åçš„æ•°æ®
        if args.output:
            logger.info(f"ğŸ’¾ ä¿å­˜éªŒè¯åçš„æ•°æ®: {args.output}")
            save_json(validated_data, args.output)
            print(f"\nğŸ’¾ éªŒè¯åçš„æ•°æ®å·²ä¿å­˜: {args.output}")
        
        # ä¿å­˜éªŒè¯æŠ¥å‘Š
        if args.report:
            logger.info(f"ğŸ“„ å¯¼å‡ºéªŒè¯æŠ¥å‘Š: {args.report}")
            validator.export_validation_report(args.report)
            print(f"ğŸ“„ éªŒè¯æŠ¥å‘Šå·²ä¿å­˜: {args.report}")
        
        return 0 if summary['success_rate'] > 0.8 else 1
        
    except Exception as e:
        error_msg = f"éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}"
        logger.error(f"âŒ {error_msg}")
        print(f"âŒ {error_msg}")
        return 1


# merge_resultså‡½æ•°å·²è¢«merge_knowledge_graph_resultsæ›¿ä»£


def check_help_request():
    """
    æ£€æŸ¥æ˜¯å¦ä¸ºå¸®åŠ©è¯·æ±‚
    Check if this is a help request
    """
    help_flags = ['-h', '--help']

    # æ£€æŸ¥å‚æ•°ä¸­æ˜¯å¦åŒ…å«å¸®åŠ©æ ‡å¿—
    for arg in sys.argv[1:]:
        if arg in help_flags:
            return True

        # æ£€æŸ¥æ˜¯å¦æ˜¯å­å‘½ä»¤çš„å¸®åŠ©è¯·æ±‚
        if arg in ['create-config', 'process', 'process-documents', 'validate']:
            # æ£€æŸ¥ä¸‹ä¸€ä¸ªå‚æ•°æ˜¯å¦æ˜¯å¸®åŠ©æ ‡å¿—
            arg_index = sys.argv.index(arg)
            if arg_index + 1 < len(sys.argv) and sys.argv[arg_index + 1] in help_flags:
                return True

    # æ²¡æœ‰å‚æ•°ä¹Ÿæ˜¾ç¤ºå¸®åŠ©
    return len(sys.argv) == 1


def conditional_log(logger, level, message):
    """
    æ¡ä»¶æ—¥å¿—è®°å½•å‡½æ•°
    Conditional logging function
    """
    if logger is not None:
        if level == 'info':
            logger.info(message)
        elif level == 'error':
            logger.error(message)
        elif level == 'warning':
            logger.warning(message)


def main():
    """ä¸»å‡½æ•° | Main function"""

    # é¢„è§£æå‚æ•°ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯å¸®åŠ©è¯·æ±‚ï¼Œé¿å…ç”Ÿæˆæ—¥å¿—æ–‡ä»¶
    is_help_request = check_help_request()

    # åªæœ‰åœ¨éå¸®åŠ©è¯·æ±‚æ—¶æ‰è¿›è¡Œæ—¥å¿—åˆå§‹åŒ–
    main_logger = None
    if not is_help_request:
        main_logger = get_logger()
        main_logger.info("ğŸš€ LLM JSON Generator CLI å¯åŠ¨")

    # ä¸­è‹±åŒè¯­å¸®åŠ©ä¿¡æ¯
    description = """
LLM JSON Generator - é€šè¿‡å¤§è¯­è¨€æ¨¡å‹ç”ŸæˆçŸ¥è¯†å›¾è°±JSONæ•°æ®
LLM JSON Generator - Generate knowledge graph JSON data using Large Language Models

ä¸»è¦åŠŸèƒ½ | Key Features:
â€¢ æ–‡æ¡£å¤„ç†: æ”¯æŒ .txt å’Œ .docx æ–‡æ¡£ | Document processing: Support .txt and .docx files
â€¢ æ‰¹é‡å¤„ç†: é«˜æ•ˆå¤„ç†å¤šä¸ªæ–‡æ¡£ | Batch processing: Efficient processing of multiple documents
â€¢ æ•°æ®éªŒè¯: JSONæ•°æ®éªŒè¯å’Œä¿®å¤ | Data validation: JSON data validation and repair
â€¢ å¹¶è¡Œå¤„ç†: å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç† | Parallel processing: Multi-threaded parallel processing
â€¢ æµå¼å¤„ç†: å®æ—¶å¤„ç†å’Œè¾“å‡º | Streaming processing: Real-time processing and output
"""

    examples = """
ä½¿ç”¨ç¤ºä¾‹ | Usage Examples:

ğŸ“‹ é…ç½®ç®¡ç† | Configuration Management:
  # åˆ›å»ºé…ç½®æ–‡ä»¶ | Create configuration file
  llm-json-generator create-config
  llm-json-generator create-config -o my_config.json

ğŸ“„ å•æ–‡æ¡£å¤„ç† | Single Document Processing:
  # åŸºç¡€å¤„ç† | Basic processing
  llm-json-generator process document.txt
  llm-json-generator process document.docx

  # è‡ªå®šä¹‰è¾“å‡ºç›®å½• | Custom output directory
  llm-json-generator process document.txt -o results/

  # ä½¿ç”¨è‡ªå®šä¹‰é…ç½® | Use custom configuration
  llm-json-generator process document.txt -c my_config.json

  # åŒ…å«è¡¨æ ¼å’ŒéªŒè¯ | Include tables and validation
  llm-json-generator process document.txt --tables --validation

  # å¯ç”¨è¯¦ç»†æ—¥å¿— | Enable detailed logging
  llm-json-generator process document.txt -l

ğŸ“ æ‰¹é‡æ–‡æ¡£å¤„ç† | Batch Document Processing:
  # ä¼ ç»Ÿæ‰¹é‡å¤„ç† | Traditional batch processing
  llm-json-generator process-documents /path/to/docs/ -m batch -o results/

  # ä¼˜åŒ–æµå¼å¤„ç†(æ¨è) | Optimized streaming processing (recommended)
  llm-json-generator process-documents /path/to/docs/ -m optimized -o results/

  # å®Œæ•´å‚æ•°ç¤ºä¾‹ | Full parameter example
  llm-json-generator process-documents /path/to/docs/ \\
    -m optimized -o batch_results/ -c my_config.json --tables --validation -l

ğŸ” æ•°æ®éªŒè¯ | Data Validation:
  # åŸºç¡€éªŒè¯ | Basic validation
  llm-json-generator validate data.json

  # ä¿å­˜éªŒè¯åçš„æ•°æ®å’ŒæŠ¥å‘Š | Save validated data and report
  llm-json-generator validate data.json -o validated_data.json -r validation_report.json

ğŸ’¡ é«˜çº§ç”¨æ³• | Advanced Usage:
  # ä½¿ç”¨è‡ªå®šä¹‰æç¤ºæ¨¡æ¿ | Use custom prompt template
  llm-json-generator process document.txt -t custom_template.json

  # å¤„ç†åŒ…å«å¤§é‡è¡¨æ ¼çš„æ–‡æ¡£ | Process documents with many tables
  llm-json-generator process-document folder/ --tables --validation -l

ğŸ¯ è¾“å‡ºè¯´æ˜ | Output Description:
  â€¢ results/ - å¤„ç†ç»“æœç›®å½• | Processing results directory
  â€¢ chunks_results.json - æ–‡æœ¬å—å¤„ç†ç»“æœ | Text chunk processing results
  â€¢ failed_chunks.json - å¤±è´¥çš„æ–‡æœ¬å— | Failed text chunks
  â€¢ validation_report.json - æ•°æ®éªŒè¯æŠ¥å‘Š | Data validation report
  â€¢ knowledge_graph.json - æœ€ç»ˆçŸ¥è¯†å›¾è°± | Final knowledge graph

âš ï¸ æ³¨æ„äº‹é¡¹ | Important Notes:
  â€¢ é¦–æ¬¡ä½¿ç”¨å‰è¯·å…ˆåˆ›å»ºé…ç½®æ–‡ä»¶ | Create configuration file before first use
  â€¢ ç¡®ä¿APIå¯†é’¥å·²æ­£ç¡®é…ç½® | Ensure API key is properly configured
  â€¢ å¤§æ–‡æ¡£å»ºè®®ä½¿ç”¨æµå¼å¤„ç† | Use streaming processing for large documents
  â€¢ å¯ç”¨æ—¥å¿—ä»¥è·å¾—è¯¦ç»†é”™è¯¯ä¿¡æ¯ | Enable logging for detailed error information
"""

    parser = argparse.ArgumentParser(
        description=description,
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=examples
    )
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤ | Available commands')

    # åˆ›å»ºé…ç½®å‘½ä»¤
    config_help = """
åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶ | Create example configuration file

æ­¤å‘½ä»¤åˆ›å»ºåŒ…å«é»˜è®¤è®¾ç½®çš„é…ç½®æ–‡ä»¶ï¼ŒåŒ…å«LLMé…ç½®å’Œå¤„ç†é…ç½®ã€‚
This command creates a configuration file with default settings, including LLM and processing configurations.

ç¤ºä¾‹ | Example:
  llm-json-generator create-config
  llm-json-generator create-config -o /path/to/my_config.json
"""
    config_parser = subparsers.add_parser('create-config',
                                         help='åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶ | Create example configuration file',
                                         description=config_help,
                                         formatter_class=argparse.RawDescriptionHelpFormatter)
    config_parser.add_argument('-o', '--output',
                             help='é…ç½®æ–‡ä»¶è¾“å‡ºè·¯å¾„ | Configuration file output path (é»˜è®¤: config.json | default: config.json)')
    config_parser.set_defaults(func=create_config_command)

    # å¤„ç†æ–‡æœ¬å‘½ä»¤
    process_help = """
å¤„ç†å•ä¸ªæ–‡æœ¬æ–‡ä»¶ | Process a single text document

å¤„ç†å•ä¸ªæ–‡æ¡£(.txtæˆ–.docx)ï¼Œæå–å®ä½“å’Œå…³ç³»ç”ŸæˆçŸ¥è¯†å›¾è°±ã€‚
Process a single document (.txt or .docx) to extract entities and relationships and generate a knowledge graph.

æ”¯æŒçš„æ ¼å¼ | Supported formats:
â€¢ çº¯æ–‡æœ¬æ–‡ä»¶ (.txt) | Plain text files (.txt)
â€¢ Wordæ–‡æ¡£ (.docx) | Word documents (.docx)

è¾“å‡ºæ–‡ä»¶ | Output files:
â€¢ knowledge_graph.json - æœ€ç»ˆçŸ¥è¯†å›¾è°± | Final knowledge graph
â€¢ chunks_results.json - æ–‡æœ¬å—å¤„ç†ç»“æœ | Text chunk processing results
â€¢ failed_chunks.json - å¤±è´¥çš„æ–‡æœ¬å— | Failed text chunks (if any)
â€¢ validation_report.json - éªŒè¯æŠ¥å‘Š | Validation report (if --validation)

ç¤ºä¾‹ | Examples:
  # åŸºç¡€å¤„ç† | Basic processing
  llm-json-generator process document.txt

  # è‡ªå®šä¹‰è¾“å‡ºç›®å½• | Custom output directory
  llm-json-generator process document.docx -o results/

  # ä½¿ç”¨è‡ªå®šä¹‰é…ç½® | Use custom configuration
  llm-json-generator process document.txt -c my_config.json

  # åŒ…å«è¡¨æ ¼å’Œå¯ç”¨éªŒè¯ | Include tables and enable validation
  llm-json-generator process document.txt --tables --validation

  # å¯ç”¨è¯¦ç»†æ—¥å¿— | Enable detailed logging
  llm-json-generator process document.txt -l
"""
    process_parser = subparsers.add_parser('process',
                                         help='å¤„ç†å•ä¸ªæ–‡æœ¬æ–‡ä»¶ | Process a single text document',
                                         description=process_help,
                                         formatter_class=argparse.RawDescriptionHelpFormatter)
    process_parser.add_argument('document_path',
                             help='æ–‡æ¡£è·¯å¾„ | Document file path (.txt or .docx)')
    process_parser.add_argument('-c', '--config',
                             help='é…ç½®æ–‡ä»¶è·¯å¾„ | Configuration file path (é»˜è®¤: config.json | default: config.json)')
    process_parser.add_argument('-o', '--output',
                             help='è¾“å‡ºç›®å½• | Output directory (é»˜è®¤: output | default: output)')
    process_parser.add_argument('-t', '--template',
                             help='æç¤ºæ¨¡æ¿æ–‡ä»¶è·¯å¾„ | Prompt template file path (é»˜è®¤: None | default: None)')
    process_parser.add_argument('--tables', action='store_true',
                             help='åŒ…å«è¡¨æ ¼ | Include tables in processing')
    process_parser.add_argument('--validation', action='store_true',
                             help='å¼€å¯æ•°æ®éªŒè¯ | Enable data validation')
    process_parser.add_argument('-l', '--log', action='store_true',
                             help='å¯ç”¨æ§åˆ¶å°æ—¥å¿—è¾“å‡º | Enable console logging output')
    process_parser.set_defaults(func=process_text_command)

    # å¤„ç†æ–‡æ¡£åˆ—è¡¨å‘½ä»¤
    docs_help = """
æ‰¹é‡å¤„ç†æ–‡æ¡£æ–‡ä»¶å¤¹ | Batch process document folder

å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡æ¡£ï¼Œæ”¯æŒä¸¤ç§å¤„ç†æ¨¡å¼ã€‚
Process all documents in a folder with two processing modes available.

å¤„ç†æ¨¡å¼ | Processing Modes:
â€¢ batch: ä¼ ç»Ÿæ‰¹é‡å¤„ç†ï¼Œä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ–‡æ¡£ | Traditional batch processing, load all documents at once
  é€‚åˆ | Suitable for: å°‘é‡æ–‡æ¡£ï¼Œå†…å­˜å……è¶³ | Few documents, sufficient memory
â€¢ optimized: ä¼˜åŒ–æµå¼å¤„ç†ï¼Œåˆ†æ‰¹æµå¼å¤„ç† | Optimized streaming processing, batch streaming
  é€‚åˆ | Suitable for: å¤§é‡æ–‡æ¡£ï¼Œå†…å­˜æœ‰é™ | Many documents, limited memory (æ¨è | recommended)

è¾“å‡ºç»“æ„ | Output Structure:
results/
â”œâ”€â”€ document1/
â”‚   â”œâ”€â”€ knowledge_graph.json
â”‚   â”œâ”€â”€ chunks_results.json
â”‚   â””â”€â”€ validation_report.json
â””â”€â”€ document2/
    â”œâ”€â”€ knowledge_graph.json
    â””â”€â”€ ...

ç¤ºä¾‹ | Examples:
  # ä¼ ç»Ÿæ‰¹é‡å¤„ç† | Traditional batch processing
  llm-json-generator process-documents /path/to/docs/ -m batch -o results/

  # ä¼˜åŒ–æµå¼å¤„ç† | Optimized streaming processing
  llm-json-generator process-documents /path/to/docs/ -m optimized -o results/

  # å®Œæ•´å‚æ•° | Full parameters
  llm-json-generator process-documents /path/to/docs/ \\
    -m optimized -o batch_results/ -c my_config.json --tables --validation -l
"""
    docs_parser = subparsers.add_parser('process-documents',
                                      help='æ‰¹é‡å¤„ç†æ–‡æ¡£æ–‡ä»¶å¤¹ | Batch process document folder',
                                      description=docs_help,
                                      formatter_class=argparse.RawDescriptionHelpFormatter)
    docs_parser.add_argument('folder_path',
                           help='åŒ…å«æ–‡æ¡£çš„æ–‡ä»¶å¤¹è·¯å¾„ | Path to folder containing documents')
    docs_parser.add_argument('-c', '--config',
                           help='é…ç½®æ–‡ä»¶è·¯å¾„ | Configuration file path (é»˜è®¤: config.json | default: config.json)')
    docs_parser.add_argument('-o', '--output',
                           help='è¾“å‡ºç›®å½• | Output directory (é»˜è®¤: output | default: output)')
    docs_parser.add_argument('-m', '--mode', choices=['batch', 'optimized'],
                           help='å¤„ç†æ¨¡å¼ | Processing mode: batch (ä¼ ç»Ÿæ‰¹é‡ | traditional batch), optimized (ä¼˜åŒ–æµå¼ | optimized streaming, é»˜è®¤ | default)')
    docs_parser.add_argument('-t', '--template',
                           help='æç¤ºæ¨¡æ¿æ–‡ä»¶è·¯å¾„ | Prompt template file path (é»˜è®¤: None | default: None)')
    docs_parser.add_argument('--tables', action='store_true',
                           help='åŒ…å«è¡¨æ ¼ | Include tables in processing')
    docs_parser.add_argument('--validation', action='store_true',
                           help='å¼€å¯æ•°æ®éªŒè¯ | Enable data validation')
    docs_parser.add_argument('-l', '--log', action='store_true',
                           help='å¯ç”¨æ§åˆ¶å°æ—¥å¿—è¾“å‡º | Enable console logging output')
    docs_parser.set_defaults(func=process_documents_command)

    # éªŒè¯æ•°æ®å‘½ä»¤
    validate_help = """
éªŒè¯JSONæ•°æ® | Validate JSON data

å¯¹JSONæ•°æ®è¿›è¡ŒéªŒè¯ã€ä¿®å¤å’Œæ¸…ç†ï¼Œç”Ÿæˆè¯¦ç»†çš„éªŒè¯æŠ¥å‘Šã€‚
Validate, repair, and clean JSON data with detailed validation reports.

éªŒè¯åŠŸèƒ½ | Validation Features:
â€¢ JSONæ ¼å¼éªŒè¯ | JSON format validation
â€¢ æ•°æ®ç»“æ„æ£€æŸ¥ | Data structure verification
â€¢ é”™è¯¯è‡ªåŠ¨ä¿®å¤ | Automatic error correction
â€¢ æ•°æ®å®Œæ•´æ€§æ£€æŸ¥ | Data integrity checking
â€¢ è¯¦ç»†æŠ¥å‘Šç”Ÿæˆ | Detailed report generation

æŠ¥å‘Šå†…å®¹ | Report Content:
â€¢ éªŒè¯æˆåŠŸç‡ | Validation success rate
â€¢ é”™è¯¯ç»Ÿè®¡ | Error statistics
â€¢ ä¿®å¤ç»Ÿè®¡ | Repair statistics
â€¢ é”™è¯¯è¯¦æƒ… | Error details
â€¢ è­¦å‘Šä¿¡æ¯ | Warning information

ç¤ºä¾‹ | Examples:
  # åŸºç¡€éªŒè¯ | Basic validation
  llm-json-generator validate data.json

  # ä¿å­˜éªŒè¯åçš„æ•°æ® | Save validated data
  llm-json-generator validate data.json -o clean_data.json

  # ç”ŸæˆéªŒè¯æŠ¥å‘Š | Generate validation report
  llm-json-generator validate data.json -r report.json

  # ä¿å­˜æ•°æ®å’ŒæŠ¥å‘Š | Save both data and report
  llm-json-generator validate data.json -o clean_data.json -r report.json
"""
    validate_parser = subparsers.add_parser('validate',
                                          help='éªŒè¯JSONæ•°æ® | Validate JSON data',
                                          description=validate_help,
                                          formatter_class=argparse.RawDescriptionHelpFormatter)
    validate_parser.add_argument('input',
                              help='è¾“å…¥JSONæ–‡ä»¶è·¯å¾„ | Input JSON file path')
    validate_parser.add_argument('-o', '--output',
                              help='éªŒè¯åæ•°æ®è¾“å‡ºè·¯å¾„ | Validated data output path')
    validate_parser.add_argument('-r', '--report',
                              help='éªŒè¯æŠ¥å‘Šè¾“å‡ºè·¯å¾„ | Validation report output path')
    validate_parser.set_defaults(func=validate_command)
    
    # è§£æå‚æ•°
    args = parser.parse_args()
    
    if not args.command:
        conditional_log(main_logger, 'info', "ğŸ“– æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯")
        parser.print_help()
        return 1
    
    # æ‰§è¡Œå‘½ä»¤
    try:
        conditional_log(main_logger, 'info', f"ğŸ“ æ‰§è¡Œå‘½ä»¤: {args.command}")
        result = args.func(args)
        conditional_log(main_logger, 'info', f"âœ… å‘½ä»¤æ‰§è¡Œå®Œæˆï¼Œé€€å‡ºç : {result}")
        return result
    except KeyboardInterrupt:
        conditional_log(main_logger, 'info', "â¹ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        print("\nâ¹ï¸  æ“ä½œå·²å–æ¶ˆ")
        return 1
    except Exception as e:
        conditional_log(main_logger, 'error', f"âŒ å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}")
        print(f"âŒ å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}")
        return 1


if __name__ == '__main__':
    sys.exit(main())