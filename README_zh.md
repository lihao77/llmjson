# LLM JSON Generator

[![Python Version](https://img.shields.io/badge/python-3.9%2B-blue.svg)](https://python.org)[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)[![PyPI Version](https://img.shields.io/badge/pypi-1.0.0-orange.svg)](#)

ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„PythonåŒ…ï¼Œä¸“ä¸ºä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆç»“æ„åŒ–JSONæ•°æ®è€Œè®¾è®¡ã€‚æ”¯æŒæ–‡æœ¬åˆ†å—ã€æ‰¹é‡å¤„ç†ã€æµå¼å¤„ç†ã€Wordæ–‡æ¡£è§£æå’Œæ•°æ®éªŒè¯ç­‰åŠŸèƒ½ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- ğŸ¤– **å¤šLLMæ”¯æŒ**: æ”¯æŒOpenAI GPTç³»åˆ—ç­‰ä¸»æµå¤§è¯­è¨€æ¨¡å‹
- ğŸ“„ **æ–‡æ¡£å¤„ç†**: æ”¯æŒçº¯æ–‡æœ¬å’ŒWordæ–‡æ¡£(.docx)å¤„ç†
- âš¡ **é«˜æ•ˆå¤„ç†**: æä¾›æ‰¹é‡å¤„ç†ã€æµå¼å¤„ç†å’Œå¹¶è¡Œå¤„ç†æ¨¡å¼
- ğŸ”§ **çµæ´»é…ç½®**: æ”¯æŒé…ç½®æ–‡ä»¶å’Œç¯å¢ƒå˜é‡é…ç½®
- âœ… **æ•°æ®éªŒè¯**: å†…ç½®JSONæ•°æ®éªŒè¯å’Œä¿®å¤åŠŸèƒ½
- ğŸ¯ **æ™ºèƒ½åˆ†å—**: è‡ªåŠ¨æ–‡æœ¬åˆ†å—ï¼Œæ”¯æŒé‡å å’Œè¡¨æ ¼å¤„ç†
- ğŸ“Š **è¿›åº¦ç›‘æ§**: å®æ—¶å¤„ç†è¿›åº¦å’Œæ€§èƒ½ç»Ÿè®¡
- ğŸ› ï¸ **CLIå·¥å…·**: æä¾›å®Œæ•´çš„å‘½ä»¤è¡Œæ¥å£
- ğŸ”„ **é”™è¯¯æ¢å¤**: è‡ªåŠ¨é‡è¯•å’Œé”™è¯¯å¤„ç†æœºåˆ¶

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
pip install llmjson
```

æˆ–ä»æºç å®‰è£…ï¼š

```bash
git clone https://github.com/lihao77/llmjson.git
cd llmjson
pip install -e .
```

### åŸºæœ¬ä½¿ç”¨

#### 1. å‘½ä»¤è¡Œå·¥å…·ï¼ˆæ¨èï¼‰

æ”¯æŒä¸¤ä¸ªå‘½ä»¤ï¼š`llmjson` å’Œ `llmgen`ï¼ˆç®€å†™å½¢å¼ï¼‰

**åˆ›å»ºé…ç½®æ–‡ä»¶ï¼š**
```bash
llmjson create-config --output config.json
# æˆ–è€…ä½¿ç”¨ç®€å†™
llmgen create-config --output config.json
```

**å¤„ç†æ–‡æœ¬æ–‡ä»¶ï¼š**
```bash
# å¤„ç†çº¯æ–‡æœ¬æ–‡ä»¶
llmjson process document.txt --config config.json --output results/

# å¤„ç†Wordæ–‡æ¡£ï¼ˆåŒ…å«è¡¨æ ¼ï¼‰
llmjson process document.docx --config config.json --tables

# å¼€å¯æ•°æ®éªŒè¯
llmjson process input.txt --config config.json --validation

# ä½¿ç”¨è‡ªå®šä¹‰æç¤ºæ¨¡æ¿
llmjson process document.txt --template my_template.txt

# å¯ç”¨è¯¦ç»†æ—¥å¿—
llmjson process document.txt --config config.json --log
```

**æ‰¹é‡å¤„ç†æ–‡æ¡£æ–‡ä»¶å¤¹ï¼š**
```bash
# æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡æ¡£
llmjson process-documents /path/to/documents/ --config config.json

# ä½¿ç”¨ä¼˜åŒ–æµå¼å¤„ç†æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
llmjson process-documents /path/to/documents/ --mode optimized

# ä½¿ç”¨ä¼ ç»Ÿæ‰¹é‡å¤„ç†æ¨¡å¼
llmjson process-documents /path/to/documents/ --mode batch

# åŒ…å«è¡¨æ ¼å¹¶ç”ŸæˆéªŒè¯æŠ¥å‘Š
llmjson process-documents /path/to/documents/ --tables --validation
```

**æ•°æ®éªŒè¯ï¼š**
```bash
# éªŒè¯JSONæ•°æ®
llmjson validate data.json

# ä¿å­˜éªŒè¯åçš„æ•°æ®
llmjson validate data.json --output cleaned_data.json

# ç”ŸæˆéªŒè¯æŠ¥å‘Š
llmjson validate data.json --report validation_report.json

# åŒæ—¶ä¿å­˜æ•°æ®å’ŒæŠ¥å‘Š
llmjson validate data.json --output cleaned_data.json --report validation_report.json
```

#### 2. Python API

```python
from llmjson import (
    LLMProcessor,
    ConfigManager,
    DataValidator,
    WordChunker,
    PromptTemplate
)

# æ–¹å¼1: ä»é…ç½®æ–‡ä»¶åŠ è½½
config = ConfigManager("config.json")
merged_config = config.get_merged_config()
processor = LLMProcessor(**merged_config)

# æ–¹å¼2: ç›´æ¥ä¼ å‚æ•°åˆå§‹åŒ–
processor = LLMProcessor(
    api_key="your-openai-api-key",
    base_url="https://api.openai.com/v1",
    model="gpt-4o-mini",
    temperature=0.1,
    max_tokens=4000,
    chunk_size=2000,
    chunk_overlap=200,
    max_workers=4,
    enable_parallel=True
)

# å¤„ç†æ–‡æœ¬
text = "ä½ çš„æ–‡æœ¬å†…å®¹..."
result, info = processor.process_chunk(text, "document_name")

if info['success']:
    print("å¤„ç†æˆåŠŸï¼")
    print(result)
else:
    print(f"å¤„ç†å¤±è´¥: {info['error']}")
```

## ğŸ“– è¯¦ç»†æ–‡æ¡£

### é…ç½®ç®¡ç†

#### é…ç½®æ–‡ä»¶ç¤ºä¾‹ (config.json)

```json
{
  "llm": {
    "api_key": "your-openai-api-key",
    "base_url": "https://api.openai.com/v1",
    "model": "gpt-4o-mini",
    "temperature": 0.1,
    "max_tokens": 4000,
    "timeout": 60,
    "max_retries": 3,
    "retry_delay": 1.0,
    "stream": false,
    "force_json": true,
    "extra_body": null
  },
  "processing": {
    "chunk_size": 2000,
    "chunk_overlap": 200,
    "max_workers": 4,
    "enable_parallel": true
  }
}
```

#### ç¯å¢ƒå˜é‡é…ç½®

```bash
export OPENAI_API_KEY="your-api-key"
export OPENAI_BASE_URL="https://api.openai.com/v1"
export OPENAI_MODEL="gpt-4o-mini"
export LLM_TEMPERATURE="0.1"
export LLM_MAX_TOKENS="4000"
export CHUNK_SIZE="2000"
export CHUNK_OVERLAP="200"
export MAX_WORKERS="4"
```

### Wordæ–‡æ¡£å¤„ç†

```python
from llmjson import WordChunker

# åˆ›å»ºWordåˆ†å—å™¨
chunker = WordChunker(
    max_tokens=2000,
    overlap_tokens=200
)

# åˆ†å—å¤„ç†Wordæ–‡æ¡£
chunks = chunker.chunk_document_with_tables("document.docx")

# å¤„ç†æ¯ä¸ªåˆ†å—
for i, chunk in enumerate(chunks):
    # chunk å·²ç»æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥å¤„ç†
    result, info = processor.process_chunk(chunk, f"document_chunk_{i}")
    if info['success']:
        print(f"å— {i+1} å¤„ç†æˆåŠŸ")
        print(f"æå–çš„å®ä½“æ•°: {len(result.get('entities', []))}")
        print(f"æå–çš„å…³ç³»æ•°: {len(result.get('relations', []))}")
```

### æ‰¹é‡å¤„ç†

```python
# å‡†å¤‡æ–‡æ¡£å—åˆ—è¡¨ (doc_name, chunk_index, chunk_content)
chunk_items = [
    ("doc1", 0, "ç¬¬ä¸€ä¸ªæ–‡æ¡£ç¬¬ä¸€å—çš„å†…å®¹..."),
    ("doc1", 1, "ç¬¬ä¸€ä¸ªæ–‡æ¡£ç¬¬äºŒå—çš„å†…å®¹..."),
    ("doc2", 0, "ç¬¬äºŒä¸ªæ–‡æ¡£ç¬¬ä¸€å—çš„å†…å®¹..."),
]

# æ‰¹é‡å¤„ç†
results = processor.batch_process(chunk_items)
for result, info in results:
    if info['success']:
        print(f"æ–‡æ¡£ {info['doc_name']} å— {info['chunk_index']} å¤„ç†æˆåŠŸ")
        print(result)
    else:
        print(f"å¤„ç†å¤±è´¥: {info['error']}")
```

### ä½¿ç”¨ DocumentProcessor å¤„ç†å®Œæ•´æ–‡æ¡£

```python
from llmjson import DocumentProcessor

# åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨
doc_processor = DocumentProcessor(
    config_path="config.json",
    template_file=None  # å¯é€‰ï¼šè‡ªå®šä¹‰æç¤ºæ¨¡æ¿æ–‡ä»¶
)

# å¤„ç†å•ä¸ªæ–‡æ¡£
result = doc_processor.process_single_document(
    document_path="document.docx",
    base_output_dir="output",
    include_tables=True,
    generate_validation_report=True
)

if result['success']:
    print(f"âœ… å¤„ç†æˆåŠŸï¼è€—æ—¶: {result['processing_time']:.2f}ç§’")
    print(f"ğŸ“¦ æ–‡æœ¬å—æ•°: {result['chunks']['total']}")
    print(f"âœ… æˆåŠŸ: {result['chunks']['successful']}")
    print(f"ğŸ·ï¸ æå–å®ä½“: {result['entities']['total']}ä¸ª")
    print(f"ğŸ”— æå–å…³ç³»: {result['relations']['total']}ä¸ª")
```

### æ•°æ®éªŒè¯

```python
from llmjson import DataValidator

# åˆ›å»ºéªŒè¯å™¨
validator = DataValidator()

# éªŒè¯JSONæ•°æ®
data = {"entities": [], "relationships": []}
summary, full_report = validator.validate_data(data)

print(f"éªŒè¯æ‘˜è¦: {summary}")
print(f"é”™è¯¯æ•°é‡: {full_report['error_count']}")
print(f"ä¿®æ­£æ•°é‡: {full_report['correction_count']}")

# å¯¼å‡ºéªŒè¯æŠ¥å‘Š
validator.export_validation_report("validation_report.json")
```

## ğŸ”§ é«˜çº§åŠŸèƒ½

### è‡ªå®šä¹‰æç¤ºæ¨¡æ¿

```python
from llmjson import PromptTemplate

# åˆ›å»ºè‡ªå®šä¹‰æ¨¡æ¿
template = PromptTemplate(
    system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†å›¾è°±æ„å»ºåŠ©æ‰‹...",
    user_prompt="è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å®ä½“å’Œå…³ç³»ï¼š\n{text}",
)

# ä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿
processor = LLMProcessor(config, prompt_template=template)
```

### æ€§èƒ½ç›‘æ§

```python
from llmjson import Timer

# ä½¿ç”¨è®¡æ—¶å™¨
timer = Timer()
timer.start()

result, info = processor.process_chunk(text, "doc")

timer.stop()
print(f"å¤„ç†è€—æ—¶: {timer.elapsed():.2f}ç§’")
print(f"æ ¼å¼åŒ–æ—¶é—´: {timer.elapsed_str()}")

# æˆ–ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
with Timer() as timer:
    result, info = processor.process_chunk(text, "doc")
print(f"å¤„ç†è€—æ—¶: {timer.elapsed():.2f}ç§’")

# è·å–å¤„ç†ç»Ÿè®¡
stats = processor.get_stats()
print(f"æ€»è¯·æ±‚æ•°: {stats['total_requests']}")
print(f"æˆåŠŸæ•°: {stats['successful_requests']}")
print(f"å¤±è´¥æ•°: {stats['failed_requests']}")
print(f"æ€»Tokenæ•°: {stats['total_tokens_used']}")
print(f"JSONè§£æé”™è¯¯: {stats['json_parsing_errors']}")
```

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

- **Python**: 3.9+
- **æ“ä½œç³»ç»Ÿ**: Windows, macOS, Linux
- **å†…å­˜**: å»ºè®®4GB+
- **ç½‘ç»œ**: éœ€è¦è®¿é—®OpenAI APIæˆ–å…¶ä»–LLMæœåŠ¡

## ğŸ“¦ ä¾èµ–åŒ…

**æ ¸å¿ƒä¾èµ–ï¼š**
- `openai>=1.35.0` - OpenAI APIå®¢æˆ·ç«¯
- `json-repair>=0.25.0` - JSONä¿®å¤å·¥å…·
- `python-docx>=1.1.0` - Wordæ–‡æ¡£å¤„ç†
- `tiktoken>=0.7.0` - Tokenè®¡ç®—
- `requests>=2.31.0` - HTTPè¯·æ±‚
- `typing-extensions>=4.0.0` - ç±»å‹æ³¨è§£æ‰©å±•

**å¯é€‰ä¾èµ–ï¼ˆç”¨äºå¼€å‘ï¼‰ï¼š**
- `pytest>=7.0.0` - å•å…ƒæµ‹è¯•
- `pytest-cov>=4.0.0` - æµ‹è¯•è¦†ç›–ç‡
- `black>=22.0.0` - ä»£ç æ ¼å¼åŒ–
- `flake8>=5.0.0` - ä»£ç æ£€æŸ¥
- `mypy>=1.0.0` - ç±»å‹æ£€æŸ¥

## ğŸ› ï¸ å¼€å‘æŒ‡å—

### å¼€å‘ç¯å¢ƒè®¾ç½®

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/lihao77/llmjson.git
cd llmjson

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# å®‰è£…å¼€å‘ä¾èµ–
pip install -e ".[dev]"

# è¿è¡Œæµ‹è¯•
pytest tests/

# ä»£ç æ ¼å¼åŒ–
black llmjson/
flake8 llmjson/
```

### é¡¹ç›®ç»“æ„

```
llmjson/
â”œâ”€â”€ llmjson/          # ä¸»åŒ…ç›®å½•
â”‚   â”œâ”€â”€ __init__.py             # åŒ…åˆå§‹åŒ–
â”‚   â”œâ”€â”€ cli.py                  # å‘½ä»¤è¡Œæ¥å£
â”‚   â”œâ”€â”€ config.py               # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ processor.py            # æ ¸å¿ƒå¤„ç†å™¨
â”‚   â”œâ”€â”€ validator.py            # æ•°æ®éªŒè¯å™¨
â”‚   â”œâ”€â”€ prompt_template.py      # æç¤ºæ¨¡æ¿
â”‚   â”œâ”€â”€ word_chunker.py         # Wordæ–‡æ¡£åˆ†å—
â”‚   â”œâ”€â”€ run_mode.py             # æ–‡æ¡£å¤„ç†è¿è¡Œæ¨¡å¼
â”‚   â”œâ”€â”€ utils.py                # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ exceptions.py           # å¼‚å¸¸å®šä¹‰
â”‚   â””â”€â”€ log/                    # æ—¥å¿—ç³»ç»Ÿ
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py
â”‚       â”œâ”€â”€ context.py
â”‚       â”œâ”€â”€ manager.py
â”‚       â””â”€â”€ setup.py
â”œâ”€â”€ setup.py                    # å®‰è£…é…ç½®
â”œâ”€â”€ requirements.txt            # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ pyproject.toml              # é¡¹ç›®é…ç½®
â”œâ”€â”€ README.md                   # é¡¹ç›®è¯´æ˜
â””â”€â”€ LICENSE                     # è®¸å¯è¯
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ¬¢è¿ç¤¾åŒºè´¡çŒ®ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork é¡¹ç›®ä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. åˆ›å»º Pull Request

### ä»£ç è§„èŒƒ

- ä½¿ç”¨ Black è¿›è¡Œä»£ç æ ¼å¼åŒ–
- ä½¿ç”¨ Flake8 è¿›è¡Œä»£ç æ£€æŸ¥
- ä½¿ç”¨ MyPy è¿›è¡Œç±»å‹æ£€æŸ¥
- ç¼–å†™å•å…ƒæµ‹è¯•è¦†ç›–æ–°åŠŸèƒ½
- æ›´æ–°ç›¸å…³æ–‡æ¡£

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ†˜ æ”¯æŒä¸åé¦ˆ

- **é—®é¢˜æŠ¥å‘Š**: [GitHub Issues](https://github.com/lihao77/llmjson/issues)
- **åŠŸèƒ½è¯·æ±‚**: [GitHub Discussions](https://github.com/lihao77/llmjson/discussions)
- **æ–‡æ¡£**: [é¡¹ç›®Wiki](https://github.com/lihao77/llmjson/wiki)
- **é‚®ç®±**: qingyuepei@foxmail.com

## ğŸ™ è‡´è°¢

æ„Ÿè°¢æ‰€æœ‰ä¸ºè¿™ä¸ªé¡¹ç›®åšå‡ºè´¡çŒ®çš„å¼€å‘è€…å’Œç”¨æˆ·ï¼

---

**æ³¨æ„**: ä½¿ç”¨æœ¬å·¥å…·éœ€è¦æœ‰æ•ˆçš„OpenAI APIå¯†é’¥ã€‚è¯·ç¡®ä¿éµå®ˆç›¸å…³æœåŠ¡æ¡æ¬¾å’Œä½¿ç”¨é™åˆ¶ã€‚