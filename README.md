# LLM JSON Generator

[![Python Version](https://img.shields.io/badge/python-3.9%2B-blue.svg)](https://python.org)[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)[![PyPI Version](https://img.shields.io/badge/pypi-1.0.0-orange.svg)](#)

ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„PythonåŒ…ï¼Œä¸“ä¸ºä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆç»“æ„åŒ–JSONæ•°æ®è€Œè®¾è®¡ã€‚æ”¯æŒæ–‡æœ¬åˆ†å—ã€æ‰¹é‡å¤„ç†ã€æµå¼å¤„ç†ã€Wordæ–‡æ¡£è§£æå’Œæ•°æ®éªŒè¯ç­‰åŠŸèƒ½ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- ğŸ¤– **å¤šLLMæ”¯æŒ**: æ”¯æŒOpenAI GPTç³»åˆ—ç­‰ä¸»æµå¤§è¯­è¨€æ¨¡å‹
- ğŸ“„ **æ–‡æ¡£å¤„ç†**: æ”¯æŒçº¯æ–‡æœ¬å’ŒWordæ–‡æ¡£(.docx)å¤„ç†
- âš¡ **é«˜æ•ˆå¤„ç†**: æä¾›æ‰¹é‡å¤„ç†ã€æµå¼å¤„ç†å’Œå¹¶è¡Œå¤„ç†æ¨¡å¼
- ğŸ”§ **çµæ´»é…ç½®**: æ”¯æŒé…ç½®æ–‡ä»¶å’Œç¯å¢ƒå˜é‡é…ç½®
- âœ… **æ•°æ®éªŒè¯**: å†…ç½®JSONæ•°æ®éªŒè¯å’Œä¿®å¤åŠŸèƒ½
- ğŸ¯ **æ™ºèƒ½åˆ†å—**: è‡ªåŠ¨æ–‡æœ¬åˆ†å—ï¼Œæ”¯æŒé‡å å’Œè¡¨æ ¼å¤„ç†
- ğŸ“Š **è¿›åº¦ç›‘æ§**: å®æ—¶å¤„ç†è¿›åº¦å’Œæ€§èƒ½ç»Ÿè®¡
- ğŸ› ï¸ **CLIå·¥å…·**: æä¾›å®Œæ•´çš„å‘½ä»¤è¡Œæ¥å£
- ğŸ”„ **é”™è¯¯æ¢å¤**: è‡ªåŠ¨é‡è¯•å’Œé”™è¯¯å¤„ç†æœºåˆ¶

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
pip install llm-json-generator
```

æˆ–ä»æºç å®‰è£…ï¼š

```bash
git clone https://github.com/lihao77/llm-json-generator.git
cd llm-json-generator
pip install -e .
```

### åŸºæœ¬ä½¿ç”¨

#### 1. å‘½ä»¤è¡Œå·¥å…·ï¼ˆæ¨èï¼‰

**åˆ›å»ºé…ç½®æ–‡ä»¶ï¼š**
```bash
llm-json-generator create-config --output config.json
```

**å¤„ç†æ–‡æœ¬æ–‡ä»¶ï¼š**
```bash
# å¤„ç†çº¯æ–‡æœ¬æ–‡ä»¶
llm-json-generator process-text input.txt --config config.json --output results/

# å¤„ç†Wordæ–‡æ¡£
llm-json-generator process-text document.docx --config config.json --streaming

# å¤„ç†æ¨¡å¼ç”±é…ç½®æ–‡ä»¶æ§åˆ¶ï¼ˆenable_parallelå’Œmax_workerså‚æ•°ï¼‰
llm-json-generator process-text input.txt --chunk-size 3000
```

**æ•°æ®éªŒè¯ï¼š**
```bash
llm-json-generator validate data.json --schema schema.json --output validation_report.json
```

#### 2. Python API

```python
from llm_json_generator import (
    LLMProcessor, 
    ConfigManager, 
    DataValidator,
    WordChunker
)

# åˆ›å»ºé…ç½®
config = ConfigManager()
config.llm_config.api_key = "your-openai-api-key"
config.llm_config.model = "gpt-4o-mini"
config.processing_config.chunk_size = 2000

# åˆå§‹åŒ–å¤„ç†å™¨
processor = LLMProcessor(config)

# å¤„ç†æ–‡æœ¬
text = "ä½ çš„æ–‡æœ¬å†…å®¹..."
result, info = processor.process_chunk(text, "document_name")

if info['success']:
    print("å¤„ç†æˆåŠŸï¼")
    print(result)
else:
    print(f"å¤„ç†å¤±è´¥: {info['error']}")
```

## ğŸ“– è¯¦ç»†æ–‡æ¡£

### é…ç½®ç®¡ç†

#### é…ç½®æ–‡ä»¶ç¤ºä¾‹ (config.json)

```json
{
  "llm_config": {
    "api_key": "your-openai-api-key",
    "base_url": "https://openrouter.ai/api/v1",
    "model": "deepseek/deepseek-chat-v3-0324:free",
    "temperature": 0.1,
    "max_tokens": 20000,
    "timeout": 60,
    "max_retries": 3,
    "retry_delay": 1.0
  },
  "processing_config": {
    "chunk_size": 2000,
    "chunk_overlap": 200,
    "max_workers": 4,
    "enable_parallel": true
  }
}
```

#### ç¯å¢ƒå˜é‡é…ç½®

```bash
export OPENAI_API_KEY="your-api-key"
export LLM_MODEL="gpt-4o-mini"
export LLM_TEMPERATURE="0.1"
export CHUNK_SIZE="2000"
export MAX_WORKERS="4"
export ENABLE_PARALLEL="true"
```

### Wordæ–‡æ¡£å¤„ç†

```python
from llm_json_generator import WordChunker

# åˆ›å»ºWordåˆ†å—å™¨
chunker = WordChunker(
    max_tokens=2000,
    overlap_tokens=200
)

# åˆ†å—å¤„ç†Wordæ–‡æ¡£
chunks = chunker.chunk_document_with_tables("document.docx")

# å¤„ç†æ¯ä¸ªåˆ†å—
for i, chunk in enumerate(chunks):
    result, info = processor.process_chunk(chunk, f"doc_chunk_{i}")
    if info['success']:
        print(f"å— {i+1} å¤„ç†æˆåŠŸ")
```

### æ‰¹é‡å’Œæµå¼å¤„ç†

```python
# å‡†å¤‡æ–‡æ¡£åˆ—è¡¨
documents = [
    ("doc1", 0, "ç¬¬ä¸€ä¸ªæ–‡æ¡£çš„å†…å®¹..."),
    ("doc2", 0, "ç¬¬äºŒä¸ªæ–‡æ¡£çš„å†…å®¹..."),
    # æ›´å¤šæ–‡æ¡£...
]

# æ‰¹é‡å¤„ç†
results = processor.batch_process(documents)
for result, info in results:
    if info['success']:
        print("å¤„ç†æˆåŠŸ")
    else:
        print(f"å¤„ç†å¤±è´¥: {info['error']}")

# æµå¼å¤„ç†ï¼ˆé€‚åˆå¤§é‡æ–‡æ¡£ï¼‰
for result, info in processor.batch_process(documents):
    if info['success']:
        # å®æ—¶å¤„ç†æ¯ä¸ªç»“æœ
        save_result(result)
```

### æ•°æ®éªŒè¯

```python
from llm_json_generator import DataValidator

# åˆ›å»ºéªŒè¯å™¨
validator = DataValidator()

# éªŒè¯JSONæ•°æ®
data = {"entities": [...], "relationships": [...]}
summary, full_report = validator.validate_data(data)

print(f"éªŒè¯æ‘˜è¦: {summary}")
print(f"é”™è¯¯æ•°é‡: {full_report['error_count']}")
print(f"ä¿®æ­£æ•°é‡: {full_report['correction_count']}")

# å¯¼å‡ºéªŒè¯æŠ¥å‘Š
validator.export_validation_report("validation_report.json")
```

## ğŸ”§ é«˜çº§åŠŸèƒ½

### è‡ªå®šä¹‰æç¤ºæ¨¡æ¿

```python
from llm_json_generator import PromptTemplate

# åˆ›å»ºè‡ªå®šä¹‰æ¨¡æ¿
template = PromptTemplate(
    system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†å›¾è°±æ„å»ºåŠ©æ‰‹...",
    user_prompt="è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å®ä½“å’Œå…³ç³»ï¼š\n{text}",
)

# ä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿
processor = LLMProcessor(config, prompt_template=template)
```

### æ€§èƒ½ç›‘æ§

```python
from llm_json_generator import Timer

# ä½¿ç”¨è®¡æ—¶å™¨
with Timer() as timer:
    result, info = processor.process_chunk(text, "doc")

print(f"å¤„ç†è€—æ—¶: {timer.elapsed:.2f}ç§’")

# è·å–å¤„ç†ç»Ÿè®¡
stats = processor.get_processing_stats()
print(f"æ€»å¤„ç†æ—¶é—´: {stats['total_time']:.2f}ç§’")
print(f"æˆåŠŸç‡: {stats['success_rate']:.1%}")
```

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

- **Python**: 3.9+
- **æ“ä½œç³»ç»Ÿ**: Windows, macOS, Linux
- **å†…å­˜**: å»ºè®®4GB+
- **ç½‘ç»œ**: éœ€è¦è®¿é—®OpenAI API

## ğŸ“¦ ä¾èµ–åŒ…

- `openai>=1.35.0` - OpenAI APIå®¢æˆ·ç«¯
- `json-repair>=0.25.0` - JSONä¿®å¤å·¥å…·
- `python-docx>=1.1.0` - Wordæ–‡æ¡£å¤„ç†
- `tiktoken>=0.7.0` - Tokenè®¡ç®—
- `requests>=2.31.0` - HTTPè¯·æ±‚

## ğŸ› ï¸ å¼€å‘æŒ‡å—

### å¼€å‘ç¯å¢ƒè®¾ç½®

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/lihao77/llm-json-generator.git
cd llm-json-generator

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# å®‰è£…å¼€å‘ä¾èµ–
pip install -e ".[dev]"

# è¿è¡Œæµ‹è¯•
pytest tests/

# ä»£ç æ ¼å¼åŒ–
black llm_json_generator/
flake8 llm_json_generator/
```

### é¡¹ç›®ç»“æ„

```
llm-json-generator/
â”œâ”€â”€ llm_json_generator/          # ä¸»åŒ…ç›®å½•
â”‚   â”œâ”€â”€ __init__.py             # åŒ…åˆå§‹åŒ–
â”‚   â”œâ”€â”€ cli.py                  # å‘½ä»¤è¡Œæ¥å£
â”‚   â”œâ”€â”€ config.py               # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ processor.py            # æ ¸å¿ƒå¤„ç†å™¨
â”‚   â”œâ”€â”€ validator.py            # æ•°æ®éªŒè¯å™¨
â”‚   â”œâ”€â”€ prompt_template.py      # æç¤ºæ¨¡æ¿
â”‚   â”œâ”€â”€ word_chunker.py         # Wordæ–‡æ¡£åˆ†å—
â”‚   â”œâ”€â”€ utils.py                # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ exceptions.py           # å¼‚å¸¸å®šä¹‰
â”œâ”€â”€ tests/                      # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ docs/                       # æ–‡æ¡£
â”œâ”€â”€ examples/                   # ç¤ºä¾‹ä»£ç 
â”œâ”€â”€ setup.py                    # å®‰è£…é…ç½®
â”œâ”€â”€ requirements.txt            # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ README.md                   # é¡¹ç›®è¯´æ˜
â””â”€â”€ LICENSE                     # è®¸å¯è¯


```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ¬¢è¿ç¤¾åŒºè´¡çŒ®ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork é¡¹ç›®ä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. åˆ›å»º Pull Request

### ä»£ç è§„èŒƒ

- ä½¿ç”¨ Black è¿›è¡Œä»£ç æ ¼å¼åŒ–
- ä½¿ç”¨ Flake8 è¿›è¡Œä»£ç æ£€æŸ¥
- ä½¿ç”¨ MyPy è¿›è¡Œç±»å‹æ£€æŸ¥
- ç¼–å†™å•å…ƒæµ‹è¯•è¦†ç›–æ–°åŠŸèƒ½
- æ›´æ–°ç›¸å…³æ–‡æ¡£

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ†˜ æ”¯æŒä¸åé¦ˆ

- **é—®é¢˜æŠ¥å‘Š**: [GitHub Issues](https://github.com/lihao77/llm-json-generator/issues)
- **åŠŸèƒ½è¯·æ±‚**: [GitHub Discussions](https://github.com/lihao77/llm-json-generator/discussions)
- **æ–‡æ¡£**: [é¡¹ç›®Wiki](https://github.com/lihao77/llm-json-generator/wiki)
- **é‚®ç®±**: qingyuepei@foxmail.com

## ğŸ™ è‡´è°¢

æ„Ÿè°¢æ‰€æœ‰ä¸ºè¿™ä¸ªé¡¹ç›®åšå‡ºè´¡çŒ®çš„å¼€å‘è€…å’Œç”¨æˆ·ï¼

---

**æ³¨æ„**: ä½¿ç”¨æœ¬å·¥å…·éœ€è¦æœ‰æ•ˆçš„OpenAI APIå¯†é’¥ã€‚è¯·ç¡®ä¿éµå®ˆç›¸å…³æœåŠ¡æ¡æ¬¾å’Œä½¿ç”¨é™åˆ¶ã€‚